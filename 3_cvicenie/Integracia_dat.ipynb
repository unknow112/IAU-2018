{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Integracia dat\n",
    "\n",
    "<!--\n",
    "navody na pouzivanie pandas, matplotlib a numpy na spracovanie dat. Niesu to informacie o tom ako robit explorativnu analyzu, ale ako pouzivat kniznice\n",
    "\n",
    "Z tohoto povyberam zaujimave casti, spojim ich s nejakou kapitolou v knihe o tom ako riesit spracovanie, cistanie dat a transformovanie dat\n",
    "http://nbviewer.jupyter.org/github/ResearchComputing/Meetup-Fall-2013/blob/master/python/lecture_10_pandas_introduction.ipynb\n",
    "http://nbviewer.jupyter.org/github/ResearchComputing/Meetup-Fall-2013/blob/master/python/lecture_11_pandas_adding_data.ipynb\n",
    "http://nbviewer.jupyter.org/github/ResearchComputing/Meetup-Fall-2013/blob/master/python/lecture_12_pandas_groupby.ipynb\n",
    "http://nbviewer.jupyter.org/github/ResearchComputing/Meetup-Fall-2013/blob/master/python/lecture_13_pandas_movies.ipynb \n",
    "http://nbviewer.jupyter.org/github/ResearchComputing/Meetup-Fall-2013/blob/master/python/lecture_14_pandas_reshape.ipynb\n",
    "http://nbviewer.jupyter.org/github/ResearchComputing/Meetup-Fall-2013/blob/master/python/lecture_15_pandas_transforming.ipynb\n",
    "http://nbviewer.jupyter.org/github/ResearchComputing/Meetup-Fall-2013/blob/master/python/lecture_21_pandas_processing.ipynb\n",
    "http://nbviewer.jupyter.org/github/ResearchComputing/Meetup-Fall-2013/blob/master/python/lecture_22_pandas_cleaning.ipynb\n",
    "\n",
    "http://nbviewer.jupyter.org/github/ResearchComputing/Meetup-Fall-2013/blob/master/python/lecture_23_titanic_example.ipynb\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "Image('ML_Workflow.PNG')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# O com nejdem hovorit\n",
    "\n",
    "* Nejdem opisovat vsetky mozne record linkage a entity mapping metody (to je minimalne na samostatnu prednasku)\n",
    "* Nejdem opisovat komplexne ETL nastroje a postupy na spajanie tabuliek a roznych databaz (na to tu mame dokonca samostatny predmet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Skusme sa pohrat s nejakymi datami"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "head data/BETR8010000800100hour.1-1-1990.31-12-2012"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "z tohoto zatial vieme asi len to, ze pojde o csv format, separator hodnot je \\t, su tam same numericke data a nemame pomenovane atributy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"data/BETR8010000800100hour.1-1-1990.31-12-2012\", sep='\\t')\n",
    "data.head()\n",
    "# Data su tvorene meraniami nejakej veliciny v jednotlivych hodinach dna. \n",
    "# Co den, to riadok. Kazda hodina ma zvlast stlpec + je tu stlpec pre nejaky flag, ktory nas nezaujima\n",
    "# su tam nejak divne hodnoty, ktore by tam asi nemali byt -999 a -9999\n",
    "# datum bude asi index\n",
    "# v subore nieje hlavicka"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"data/BETR8010000800100hour.1-1-1990.31-12-2012\"\n",
    "\n",
    "data = pd.read_csv(filename, sep='\\t', header=None,\n",
    "                   na_values=[-999, -9999], index_col=0)\n",
    "# vela upratovania dat vieme spravit uz pri nacitani\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# skusime povyhadzovat tie flagy, ktore nas nezaujimaju. Zhodou okolnosti je to kazdy druhy stlpec\n",
    "data.columns[1::2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop(data.columns[1::2], axis=1)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Skusme si nejak normalne poemnvoat vzniknute stlpce\n",
    "[\"{:02d}\".format(i) for i in range(len(data.columns))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mam nejako rozsypane nazvy stlpcov\n",
    "data.columns = [\"{:02d}\".format(i) for i in range(len(data.columns))]\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.stack()\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(data) # vysledok preusporiadania je viacdimenzionaly Series objekt a nie DataFrame. Ja chcem mat pekny data frame, tak s tim nieco spravime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mohli by sme nejak normalne pomenovat stlpec\n",
    "# napriklad nazvom stanice\n",
    "import os\n",
    "_, fname = os.path.split(filename)\n",
    "station = fname[:7]\n",
    "print(filename)\n",
    "print(station)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.reset_index(name=station) #reset index mi z toho sprav data frame\n",
    "# data = data.reset_index() #reset index mi z toho sprav data frame\n",
    "print(type(data))\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.rename(columns = {0:'date', 'level_1':'hour'})\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# teraz tomu vyrobime novy index z datumu a hodiny\n",
    "data.index = pd.to_datetime(data['date'] + ' ' + data['hour'])\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a zmazeme nepotrebne stlpce\n",
    "data = data.drop(['date', 'hour'], axis=1)\n",
    "data.head()\n",
    "# Teraz uz mame data, s ktorymi sa uz da nieco robit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ja mam tych suborov viac. Kazdy obsahuje data z inej meracej stanice. Aby som zjednodusil prezentaciu, tak predchadzajuci kod som dal do cyklu a vlozil do skriptu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import airbase\n",
    "no2 = airbase.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "no2.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "no2.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "no2.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "no2.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "no2.plot(kind='box')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# boxplot vie ukazat aj outlierov\n",
    "sns.boxplot(no2, sym='k.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tych outlierov by som mal normalne vidiet aj v tom klasickom boxplote, ale je nejaky bug vo verzii matplotlibu, ktoru mam nainstalovanu a zle interaguje s importovanou kniznicou seaborn. Preto som ich radsej ukazal v kniznici seaborn. Ak by som ju ale vobec nenaimportotavl, tak by tam tie outliery mali byt. \n",
    "Vraj je to uz v najnovsej verzii matplotlibu opravene :("
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "no2['BETN029'].plot(kind='hist', bins=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seaborn.violinplot(no2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "no2.plot(figsize=(12,6))\n",
    "# mozem si vyplotovat surove data, ale je otazne, co mi to povie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mozem si povedat, ze chcem len nejaku mensiu cast\n",
    "no2[-500:].plot(figsize=(12,6))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "alebo pouzijem zaujimavejsie operacie s casovymi radmi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "no2.index # kedze index su casy, tak viem robit s nimi zaujimave veci"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "no2[\"2010-01-01 09:00\": \"2010-01-01 12:00\"] # napriklad definovat rozsahy pomocou stringu s datumom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "no2['2012'] # alebo takto vybrat vsetky data z jedneho konkretneho roku\n",
    "# no2['2012'].head()\n",
    "# no2['2012/03'] # alebo len data z marca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# komponenty datumu su pristupne z indexu\n",
    "# no2.index.hour\n",
    "no2.index.year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a co je zaujimavejsie viem zmenit vzorkovaciu frekvenciu\n",
    "no2.resample('D').mean().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "no2.resample('M').mean().plot()\n",
    "# toto sa zda, ze povie uz trochu viac. Napriklad, ze je tu asi nejaka sezonnost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "no2.resample('A').mean().plot()\n",
    "# a mozno aj nejaky dlhodoby trend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "no2['2012-3':'2012-4'].resample('D').mean().plot()\n",
    "# mozno je tam aj nejaka tyzdenna sezonnost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mozem pouzit aj viacero agregacnych funkcii a porovnat si ich\n",
    "no2.loc['2009':, 'FR04037'].resample('M').agg(['mean', 'median']).plot()\n",
    "# no2.loc['2009':, 'FR04037'].resample('M').agg(['mean', 'std']).plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pozor resample != groupby"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "no2.resample('M').mean().plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "no2.groupby(no2.index.month).mean().plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Zopar uloh na groupby"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Otazka: ako by ste vyplotovali typycky denny priebeh hodnoty pre rozne stanice?\n",
    "<!--\n",
    "no2.groupby(no2.index.hour).mean().plot()\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Otazka: aky je rozdiel v priebehu hodnot medzi typickym dnom v tyzdni a cez vikend pre stanicu FR04012?\n",
    "<!--\n",
    "no2['weekday'] = no2.index.weekday\n",
    "no2['weekend'] = no2['weekday'].isin([5, 6])\n",
    "data_weekend = no2.groupby(['weekend', no2.index.hour]).mean()\n",
    "data_weekend_FR04012 = data_weekend['FR04012'].unstack(level=0)\n",
    "data_weekend_FR04012.plot()\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Priklad analyzy s pouzitim ineho datasetu\n",
    "tentokrat to nebudu casove rady, ale klasicky dataset na predvadzanie kalsifikacie Iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_data = pd.read_csv('data/iris-data.csv')\n",
    "iris_data.head()\n",
    "# toto je trochu spotvoreny dataset kvetiniek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seaborn.pairplot(iris_data.dropna(), hue='class')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_data.loc[iris_data['class'] == 'versicolor', 'class'] = 'Iris-versicolor'\n",
    "iris_data.loc[iris_data['class'] == 'Iris-setossa', 'class'] = 'Iris-setosa'\n",
    "\n",
    "iris_data['class'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seaborn.pairplot(iris_data.dropna(), hue='class')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_data.loc[iris_data['class'] == 'Iris-versicolor', 'sepal_length_cm'].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rc(\"lines\", markeredgewidth=0.5)\n",
    "iris_data.loc[iris_data['class'] == 'Iris-versicolor', 'sepal_length_cm'].plot(kind='box')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_data.loc[(iris_data['class'] == 'Iris-versicolor') & (iris_data['sepal_length_cm'] < 1 ), 'sepal_length_cm']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_data.loc[(iris_data['class'] == 'Iris-versicolor') & (iris_data['sepal_length_cm'] > 1 ), 'sepal_length_cm']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mask = (iris_data['class'] == 'Iris-versicolor') & (iris_data['sepal_length_cm'] < 1 )\n",
    "\n",
    "iris_data.loc[mask, 'sepal_length_cm'] = iris_data.loc[mask, 'sepal_length_cm'] * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_data.loc[mask, 'sepal_length_cm']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seaborn.pairplot(iris_data.dropna(), hue='class')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Skusme sa pozriet este na tie chybajuce hodnoty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_data.loc[(iris_data['sepal_length_cm'].isnull()) |\n",
    "              (iris_data['sepal_width_cm'].isnull()) |\n",
    "              (iris_data['petal_length_cm'].isnull()) |\n",
    "              (iris_data['petal_width_cm'].isnull())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_data.loc[iris_data['class'] == 'Iris-setosa', 'petal_width_cm'].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "average_petal_width = iris_data.loc[iris_data['class'] == 'Iris-setosa', 'petal_width_cm'].mean()\n",
    "\n",
    "iris_data.loc[(iris_data['class'] == 'Iris-setosa') &\n",
    "              (iris_data['petal_width_cm'].isnull()),\n",
    "              'petal_width_cm'] = average_petal_width"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seaborn.pairplot(iris_data, hue='class')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Iny sposob nahradzania prazdnych hodnot\n",
    "Pozor, toto je len najjednoduchsia moznost, kde nahradzam chybajucu hodnotu nejakou konstantou. Existuje velmi vela dalsich metod, ktore by ste mali pouzit aj vo svojom projekte."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('https://raw.githubusercontent.com/rasbt/python_reference/master/Data/some_soccer_data.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predtym sme to robili manulane. \n",
    "# iris_data.loc[(iris_data['class'] == 'Iris-setosa') & (iris_data['petal_width_cm'].isnull()), 'petal_width_cm'] = average_petal_width\n",
    "\n",
    "# Da sa na to pouzit takato pekna funkcia\n",
    "df.fillna(value=0, inplace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Existuje vsak este elegantnejsi sposob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('https://raw.githubusercontent.com/rasbt/python_reference/master/Data/some_soccer_data.csv')\n",
    "df = df.rename(columns={'P': 'points', \n",
    "                        'GP': 'games',\n",
    "                        'SOT': 'shots_on_target',\n",
    "                        'G': 'goals',\n",
    "                        'PPG': 'points_per_game',\n",
    "                        'A': 'assists',})\n",
    "df['SALARY'] = df['SALARY'].apply(lambda x: x.strip('$m'))\n",
    "\n",
    "def process_player_col(text):\n",
    "    name, rest = text.split('\\n')\n",
    "    position, team = [x.strip() for x in rest.split(' — ')]\n",
    "    return pd.Series([name, team, position])\n",
    "\n",
    "df[['PLAYER', 'team', 'position']] = df.PLAYER.apply(process_player_col)            \n",
    "               \n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# v kniznici sklearn uz su predpripravene nejake metody na nahradzanie chybajucich hodnot\n",
    "from sklearn.preprocessing import Imputer\n",
    "imp = Imputer(missing_values='NaN', strategy='mean', axis=0)\n",
    "df[['games', 'assists']] = imp.fit_transform(df[['games', 'assists']].values)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pozor, toto doplnanie neberie do uvahy triedu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.games.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.position == 'Forward'].games.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cize mozno by bolo lepsie spravit trochu inteligentnejsie nahradzanie chybajucich hodnot, ktore pocita oddelene priemery pre rozne skupiny hracov. Toto sa vola nahradenie chýbajúcej hodnoty priemerom segmentu (je to jedna z moznosti, ktoru by ste mali vyskusat v druhej casti projektu)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sumar co si zobrat z tejto explorativnej analyzy\n",
    "\n",
    "* Uisite sa, ze data su kodovane spravne (najcastejsie sa treba pozriet manualne do dat)\n",
    "* Uistite sa, ze data spadaju do ocakavaneho rozsahu a vsetky maju ocakavany tvar (napriklad format casu)\n",
    "* Porieste chybajuce data napriklad vyhodenim, nahradenim priemerom (priemer moze byt s ohladom na triedu), ...\n",
    "* Nikdy nesahajte do dat manualne. Vzdy pouzivajte kod, ktory si odlozite a pouzijete vzdy ked budete opakovat experiment. Chceme aby bola analyza reprodukovatelna\n",
    "* Spravte si grafy vsetkeho, co sa len da, aby ste si vizualne potvrdili, ze nieco je tak ako by malo byt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
